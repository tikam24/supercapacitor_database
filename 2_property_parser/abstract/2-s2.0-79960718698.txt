A method for finding optimal control policies for first order state-constrained stochastic dynamic systems in continuous time is presented. The method relies on solution of the Hamilton-Jacobi-Bellman equation, which includes a diffusion term related to the stochastic disturbance in the model. A variable transformation is applied that turns the infinite-horizon optimal control problem into a linear eigenvalue problem in state-space. The method is demonstrated on a buffer control problem for a fuel cell-supercapacitor system. The obtained closed-form solution explains the shape of previous heuristically found control laws for this type of problem. Copyright Â© 2005 IFAC.