import os
import re
import pandas as pd
from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline
model_name = "batterydata/batterybert-cased-abstract"


# Path to the abstract folder
folder_path = r"C:\Users\Tikam Soni\@SC_DB_Codes\abstract"  # Replace with the path to your folder

# Get a list of all files in the folder
file_list = os.listdir(folder_path)


def split_text_into_chunks(text, chunk_size=512):
    words = re.findall(r'\b\w+\b', text) # Split the text into words using whitespace as a delimiter

    chunks = []  # Initialize an empty list to store the chunks

    current_chunk = []  # Initialize a variable to keep track of the current chunk

    # Loop through the words and create chunks of the specified size
    for word in words:
        current_chunk.append(word)
        
        # Check if the current chunk size has reached the specified limit
        if len(current_chunk) >= chunk_size:
            # Join the words in the current chunk into a single string
            chunk_text = ' '.join(current_chunk)
            
            # Append the chunk to the list of chunks
            chunks.append(chunk_text)
            
            # Reset the current chunk
            current_chunk = []

    # If there are any remaining words in the current chunk, add them to the list
    if current_chunk:
        chunk_text = ' '.join(current_chunk)
        chunks.append(chunk_text)

    return chunks


df = pd.DataFrame()
nlp = pipeline('text-classification', model=model_name, tokenizer=model_name)

for file_name in file_list:
    if file_name.endswith(".txt"):  # Process only text files
        file_path = os.path.join(folder_path, file_name)  # Get the full file path
        with open(file_path, "r", encoding="utf8") as file:
            content = file.read()
            input1 = str(split_text_into_chunks(content, chunk_size=510)[0])
            try:
                res = nlp(input1)
            except RuntimeError:
                pass
            fin = res[0]
            fin.__setitem__('EID', file_name[:-4])
            df = df._append(fin, ignore_index=True)
            print(fin)


df.head()

# Save the DataFrame to Excel
df.to_excel('labeled_bert.xlsx', index=False, header=True)


# Filter out rows with 'TypeB'
filtered_df = df[df['label'] != 'non-battery']

# Display the new DataFrame without 'TypeB'
print(filtered_df)

# Save the DataFrame to Excel
df.to_excel('clasified_bert.xlsx', index=False, header=True)



